models:
  - "meta-llama/Meta-Llama-3.1-8B-Instruct"
  - "google/gemma-3-27b-it"
  - "meta-llama/Meta-Llama-3.1-70B-Instruct"
  - "openai/gpt-oss-120b"

temperature: 0.7
timeout: 30
max_retries: 2
max_tokens: 1024
model_provider: "openai"
base_url: "https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1"
api_key: ""

parallelism:
  max_workers: 4

prompting:
  n_few_shots:
    - 1
    - 2
    - 4
    - 8
  cot: [false, true]